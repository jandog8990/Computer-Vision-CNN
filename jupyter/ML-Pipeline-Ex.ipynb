{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Assignment\n",
    "\n",
    "Pipeline() is used for evaluating different options and different models.\n",
    "\n",
    "## Basic Understanding\n",
    "After covering this material, we need to answer the following questions:\n",
    " 1. Why is it wrong to say that y can be predicted from X?\n",
    " 2. What is wrong with applying the steps in order?\n",
    " 3. Why do the training sets overlap the testing sets?\n",
    " 4. Why does the pipeline avoid the issue?\n",
    " \n",
    "## Modify the code to understand the trend\n",
    "Small number of features:\n",
    " 1. Reduce the number of components of X by 100.\n",
    " 2. In the Kernel submenu, click \"Restart & Run All\" to rerun.\n",
    " 3. What are the new values for $R^2$?\n",
    " 4. Are the new values lower or higher? Explain.\n",
    "\n",
    "Modify the code to: \n",
    " 1. Increase the number of components of X by 10 to 1000\n",
    " 2. Rerun.\n",
    " 3. What is the relationship between the number of components and $R^2$?\n",
    "\n",
    "## Model pipeline optimization\n",
    " 1. How did we pass parameters to different models?\n",
    " 2. What is the advantage of using a single call to GridSearchCV()?\n",
    " \n",
    " \n",
    "The example is taken from Chapter 6 of an Introduction to Machine Learning with Python\n",
    "[Github for book code](https://github.com/amueller/introduction_to_ml_with_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has 100 observations of 100-dimensional vectors\n",
      "y has 100 responses.\n"
     ]
    }
   ],
   "source": [
    "# NumPy library:\n",
    "import numpy as np\n",
    "\n",
    "# Create uncorrelated Random Variables:\n",
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 100))\n",
    "y = rnd.normal(size=(100,))\n",
    "\n",
    "print('X has {} observations of {}-dimensional vectors'.format(X.shape[0], X.shape[1]))\n",
    "print('y has {} responses.'.format(y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Linear regression is performed using:\n",
    "\n",
    "       y = m*X[i] + c\n",
    "       \n",
    "where the goal is to predict y from the ith-feature in X.\n",
    "\n",
    "For the F-value, we are measuring the p-values, the probability that \"m\" is zero by random chance. Thus, a low-value indicates that \"m\" is not zero. \n",
    "\n",
    "In selecting percentiles, each column of X is sorted from low to high. The top-5 percentile means that 95\\% of the values fall below it.\n",
    "\n",
    "ScikitLearn references for feature selection:\n",
    "[percentiles option](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html),\n",
    "[fitting using f_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html).\n",
    "[pre-processing](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_selected.shape: (100, 5)\n",
      "Transformed X has mean=-0.010 and stdev=0.988\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection Example.\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "# f_regression: \n",
    "#   1. Predicts y from X using the .fit() function.\n",
    "#   2. Computes the F-value for each one of the regression variables.\n",
    "#   3. Return the features in X that best predict the output.\n",
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y)\n",
    "\n",
    "# Standardize the variable to zero-mean standard deviation=1.\n",
    "X_selected = select.transform(X)\n",
    "\n",
    "print(\"X_selected.shape: {}\".format(X_selected.shape))\n",
    "print(\"Transformed X has mean={:0.3f} and stdev={:0.3f}\".format(np.mean(X_selected), np.std(X_selected)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression estimate y using a reduced number of variables:\n",
    "$$ || y - X w || + \\alpha || w ||_2^2 $$\n",
    "\n",
    "SciKit Learn:\n",
    "[Cross Validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "[Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "[Ridge regression example](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy (cv only on ridge): 0.13\n",
      "This mean R-squared result is wrong. Why?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Cross-validation accuracy (cv only on ridge): {:.2f}\".format(\n",
    "      np.mean(cross_val_score(Ridge(), X_selected, y, cv=5))))\n",
    "print(\"This mean R-squared result is wrong. Why?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared values: [-0.72450081 -0.25121839 -0.75010265 -0.33567149 -0.74246843]\n",
      "Cross-validation accuracy (pipeline): -0.56\n",
      "Why is this the correct result?\n"
     ]
    }
   ],
   "source": [
    "# Use pipeline to estimate correlations correctly\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"select\", SelectPercentile(score_func=f_regression,\n",
    "                                             percentile=5)),\n",
    "                 (\"ridge\", Ridge())])\n",
    "\n",
    "corrected_result = cross_val_score(pipe, X, y, cv=5)\n",
    "print(\"R-squared values:\", corrected_result)\n",
    "\n",
    "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(\n",
    "      np.mean(corrected_result)))\n",
    "print(\"Why is this the correct result?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Examine the ridge parameters withing the pipeline:\n",
    "print(pipe.named_steps[\"ridge\"].get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model optimization\n",
    "Allows us to select among different classifiers and different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False), 'classifier__C': 10, 'classifier__gamma': 0.01, 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "\n",
      "Best cross-validation score: 0.99\n",
      "Test-set score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), \n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [SVC()], \n",
    "     'preprocessing': [StandardScaler(), None],\n",
    "     'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {'classifier': [RandomForestClassifier(n_estimators=100)],\n",
    "     'preprocessing': [None], \n",
    "     'classifier__max_features': [1, 2, 3]}]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
